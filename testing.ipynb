{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a40fd5-b4bb-469f-a359-8531f962b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('src').resolve()))\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from src.dataloader import SG_Dataset\n",
    "from src.models import Skipgram_SM\n",
    "from torch.utils.data import DataLoader, ConcatDataset, BatchSampler, Sampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de842cd7-2403-4755-989f-fcd717dd6d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens loaded\n"
     ]
    }
   ],
   "source": [
    "data = open('data/shakespeare_normalized.txt', 'r').read()\n",
    "words = set(data.split())\n",
    "vocab_size = len(words)\n",
    "# When working with sents I can use this itertools.chain.from_iterable(sents) to trasnform to words \n",
    "word2id = {word: i for i, word in enumerate(words)}\n",
    "id2word = {i: word for i, word in enumerate(words)} # for future use\n",
    "print('tokens loaded')\n",
    "freq = Counter(data.split())\n",
    "min_freq = 1 # I implemented this for the future but right now I don't need it because my data is pretty small\n",
    "id_sents = [[word2id[word] for word in sent.split(' ') if freq[word] >= min_freq] for sent in data.split('\\n')]\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c618da8f-7f25-4318-ae28-5c6c69112b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(id_sents, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da95eeff-60af-4225-8430-bda9ff6334ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers, contexts = [], []\n",
    "for ids in id_sents[:]:\n",
    "    len_ids = len(ids)\n",
    "    center, context = ids, [[] for _ in range(len_ids)]\n",
    "    for i in range(len_ids):\n",
    "        begin = max(0, i - window_size)\n",
    "        for j in range(begin, i):\n",
    "            context[i].append(ids[j])\n",
    "            context[j].append(ids[i])\n",
    "    # print(center, context)\n",
    "    centers.extend(center)\n",
    "    contexts.extend(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57487a74-0dcf-469d-878d-e74f6da56da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_contexts = list(zip(centers, contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d143758e-e9f0-4e07-add7-592e3e085d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [[[], []] for _ in range(window_size * 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f693d6-2763-4acf-8e10-954a4022ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for center, context in centers_contexts:\n",
    "    if context:\n",
    "        d[len(context) - 1][0].append(center)\n",
    "        d[len(context) - 1][1].append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e52bd9-084b-43e8-9cad-5f983f257789",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [SG_Dataset(centers, np.stack(contexts)) for centers, contexts in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e072586-bb5b-43fe-afd8-fa0f82537840",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33ec126-796d-4995-a291-079e033b8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SG_Softmax_Batch_Sampler(Sampler):\n",
    "    \"\"\"A Sequential BatchSampler for Skipgram_SM CumulativeDataset\n",
    "    For more information: https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#BatchSampler\n",
    "    \"\"\"\n",
    "    def calculate_len(self):\n",
    "        # Below is code to count the length of the DataLoader\n",
    "        # I put it here because I don't want to recalculate it constantly\n",
    "        cum_len = 0\n",
    "        prev_size = 0\n",
    "        for cum_size, batch_size in zip(self.cumulative_sizes, self.batch_sizes):\n",
    "            curr_size = cum_size - prev_size\n",
    "            cum_len = (curr_size + batch_size - 1) // batch_size\n",
    "            prev_size = cum_size\n",
    "        self.cum_len = cum_len\n",
    "    def __init__(self, cumulative_sizes, batch_size):\n",
    "        self.cumulative_sizes = cumulative_sizes\n",
    "        print(self.cumulative_sizes)\n",
    "        self.batch_sizes = [0] * len(cumulative_sizes)\n",
    "        for i in range(len(cumulative_sizes)):\n",
    "            self.batch_sizes[i] = max(1, round(batch_size/(i + 1)))\n",
    "        self.calculate_len()\n",
    "    def __len__(self):\n",
    "        return self.cum_len\n",
    "    def __iter__(self):\n",
    "        prev_size = 0\n",
    "        for size, batch_size in zip(self.cumulative_sizes, self.batch_sizes):\n",
    "            batch = [0] * batch_size\n",
    "            idx_in_batch = 0\n",
    "            # Begin sequential sampling\n",
    "            for i in range(prev_size, size):\n",
    "                batch[idx_in_batch] = i\n",
    "                idx_in_batch += 1\n",
    "                if idx_in_batch == batch_size:\n",
    "                    yield batch\n",
    "                    idx_in_batch = 0\n",
    "                    # The line below I found in the pytorch implementation of BatchSampler. It seems to me that it's not necessary\n",
    "                    # batch = [0] * self.batch_size\n",
    "            if idx_in_batch > 0:\n",
    "                yield batch[:idx_in_batch]\n",
    "            prev_size = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b0a526-b3e5-4b2e-89f1-3505ea2475da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1806, 12724, 21164, 66934]\n"
     ]
    }
   ],
   "source": [
    "batch_sampler = SG_Softmax_Batch_Sampler(cd.cumulative_sizes, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32385a1c-eb33-47cf-bc96-4a3dd82e3a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610.811755952381"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1869 / 64 + (12724 - 1806) / 32 +  21228 / (round(64/3) * 3) + 66934 / 64# 2861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60c9c793-0903-478a-87ca-84a4e5d0d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1806, 12724, 21164, 66934]\n"
     ]
    }
   ],
   "source": [
    "D = DataLoader(cd, batch_sampler=SG_Softmax_Batch_Sampler(cd.cumulative_sizes, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65933a63-0240-4bba-81c7-dbf3efd5c0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.4146, grad_fn=<DivBackward0>)\n",
      "tensor(9.2174, grad_fn=<DivBackward0>)\n",
      "tensor(9.3472, grad_fn=<DivBackward0>)\n",
      "tensor(9.3097, grad_fn=<DivBackward0>)\n",
      "tensor(9.1806, grad_fn=<DivBackward0>)\n",
      "tensor(9.3777, grad_fn=<DivBackward0>)\n",
      "tensor(9.2503, grad_fn=<DivBackward0>)\n",
      "tensor(9.4274, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "from torch.nn.functional import softmax\n",
    "from torch import optim\n",
    "model = Skipgram_SM(vocab_size, 10)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "j = 0\n",
    "times = 5\n",
    "lr = 0.025\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "for X, y in D:\n",
    "    optimizer.zero_grad()\n",
    "    batch_size, context_len = y.shape\n",
    "    if context_len == 2:\n",
    "        continue\n",
    "    preds = model(X)\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(context_len):\n",
    "        loss += loss_fn(preds, y[:, i])\n",
    "        # print(softmax(preds[0]).mean())\n",
    "    loss /= (batch_size * context_len)\n",
    "    j += 1\n",
    "    if j % 400 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "701f0662-ac97-4edd-9540-cb60f48a8702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6780\n"
     ]
    }
   ],
   "source": [
    "print(len(id_sents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
