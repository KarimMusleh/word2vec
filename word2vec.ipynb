{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a74259fe-0dc6-4b71-89fc-6ad092158fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch import nn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd40b81f-7bd8-4a07-a37a-2946970a36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_braces(text):\n",
    "    result = []\n",
    "    stack = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        if text[i] == '{':\n",
    "            stack.append(i)  # Push the index of the opening brace\n",
    "        elif text[i] == '}':\n",
    "            if stack:\n",
    "                stack.pop()  # Pop the matching opening brace\n",
    "            else:\n",
    "                result.append(text[i])  # No matching opening brace, add to result\n",
    "        elif not stack:\n",
    "            result.append(text[i])  # Only add to result if not inside a pair of braces\n",
    "        i += 1\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "def filter_dataset(dataset):\n",
    "    # I may have filtered too hard\n",
    "    # I removed everything between braces because that's just LateX I tried using regex but couldn't get it to work\n",
    "    # Then I removed empty lines and lines that don't start with an upper case (removing this results in a bunch of random letters in the dataset)\n",
    "    filtered_dataset = remove_braces(dataset)\n",
    "    filtered_dataset = '\\n'.join([line for line in filtered_dataset.splitlines() if line.strip() and line[0].isupper() and len(line) > 30])\n",
    "    re.sub('https:\\/\\/[^\\s]+', '', dataset)\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc12ace9-c661-4587-8420-8869451f5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name: str, force_filter=False):\n",
    "    from pathlib import Path\n",
    "    if Path('filtered_' + name).exists() and not force_filter:\n",
    "        return open('filtered_'+name, 'r').read()\n",
    "    filtered_dataset = filter_dataset(open(name, 'r').read())\n",
    "    with open('filtered_'+dataset_name, 'w') as o:\n",
    "        o.write(filtered_dataset)\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14307a76-a828-4041-ba5d-d61a553b2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dataset.txt'\n",
    "dataset = load_dataset(dataset_name,force_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd8cff5c-4c95-4405-98c0-a640f139bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_norm=1):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            max_norm=max_norm\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=embedding_dim, out_features=vocab_size)\n",
    "    def forward(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43bd2b88-315e-4b79-80ae-9e03105beb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Statistics',\n",
       " 'and',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " '(',\n",
       " 'mathematical',\n",
       " 'programming',\n",
       " ')',\n",
       " 'methods',\n",
       " 'comprise',\n",
       " 'the',\n",
       " 'foundations',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'Data',\n",
       " 'mining',\n",
       " 'is',\n",
       " 'a',\n",
       " 'related',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " ',',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'exploratory',\n",
       " 'data',\n",
       " 'analysis',\n",
       " '(',\n",
       " 'EDA',\n",
       " ')',\n",
       " 'via',\n",
       " 'unsupervised',\n",
       " 'learning',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(dataset.splitlines()[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
