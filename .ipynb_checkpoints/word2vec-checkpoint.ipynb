{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74259fe-0dc6-4b71-89fc-6ad092158fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/micromamba/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789143830/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import torch\n",
    "from torch import optim\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "from random import uniform\n",
    "\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd40b81f-7bd8-4a07-a37a-2946970a36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    # I may have filtered too hard\n",
    "    # I removed everything between braces because that's just LateX I tried using regex but couldn't get it to work\n",
    "    # Then I removed empty lines and lines that don't start with an upper case (removing this results in a bunch of random letters in th\n",
    "    filtered_dataset = dataset\n",
    "    # print(f'The dataset is size {len(filtered_dataset)} without filtering')\n",
    "    # with open('latex.txt', 'w') as w: # use this to test wether it removes too much or too little\n",
    "    #     w.write(''.join(re.findall(r' {6}\\n {8}.*?(?:\\\\displaystyle|\\\\textstyle).*?\\n', filtered_dataset, flags=re.DOTALL)))\n",
    "    filtered_dataset = re.sub(r' {8}.*?(?:\\\\displaystyle|\\\\textstyle).*?\\n', '', filtered_dataset, flags=re.DOTALL) # We lowercase the d\n",
    "    # print(f'The dataset is size {len(filtered_dataset)} without the LaTeX')\n",
    "    # print(f\"There are currently {len(re.findall(r'displaystyle', filtered_dataset))} LaTeX blocks that have to be manually deleted\")\n",
    "    # filtered_dataset = '\\n'.join([line for line in filtered_dataset.splitlines() if line.strip()]) #  and line[0].isupper() and len(li\n",
    "    # print(len(filter_dataset))\n",
    "    filtered_dataset = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,4}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', '', filtered_dataset, re.DOTALL)\n",
    "    # print(f'The dataset is size {len(filtered_dataset)} without the links')\n",
    "    # I found the regex above here https://regexr.com/37i6s\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc12ace9-c661-4587-8420-8869451f5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name: str, force_filter=False):\n",
    "    from pathlib import Path\n",
    "    if Path('filtered_' + name).exists() and not force_filter:\n",
    "        return open('filtered_'+name, 'r').read()\n",
    "    wikis = open(name, 'r').read().split('__WIKI__')\n",
    "    wikis = [filter_dataset(wiki) for wiki in wikis]\n",
    "    with open('filtered_'+dataset_name, 'w') as o:\n",
    "        o.write('__WIKI__'.join(wikis))\n",
    "    return wikis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14307a76-a828-4041-ba5d-d61a553b2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'small_dataset.txt' # CHOOSING WIKIPEDIA WAS A MISTAKE t\n",
    "dataset = load_dataset(dataset_name,force_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd8cff5c-4c95-4405-98c0-a640f139bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_norm=1):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            max_norm=max_norm\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=embedding_dim, out_features=vocab_size)\n",
    "    def forward(self, inputs):\n",
    "        return self.linear(self.embed(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43bd2b88-315e-4b79-80ae-9e03105beb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize = RegexpTokenizer(r'\\w+').tokenize\n",
    "tokenized_dataset = [[word_tokenize(sent) for sent in sent_tokenize(wiki)] for wiki in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa1b510-30c1-4da0-922b-aef5df7e93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = [[[word.lower() for word in sent] for sent in wiki] for wiki in tokenized_dataset]\n",
    "# I should probably do this earlier but as of now I am not sure where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f994354b-e125-449b-abdf-b59538c3a4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7909b848-3ac9-4616-93de-569a1b8d3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "idx = 0\n",
    "for wiki in tokenized_dataset:\n",
    "    for sent in wiki:\n",
    "        for word in sent:\n",
    "            if word not in word2id:\n",
    "                word2id[word] = idx\n",
    "                idx += 1\n",
    "id2word = {word2id[word]: word for word in word2id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5a1d29-dbca-47c4-811c-3c7e69aef3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42396\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2id)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4706ffad-4d68-4268-af94-75ac589d4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(ids):\n",
    "    return ' '.join([id2word[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00644657-8adf-4c52-bf83-ac0246f0ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [[[word2id[word] for word in sent] for sent in wiki] for wiki in tokenized_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97ced61-10ab-41a0-a3e2-95c71c3a6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [sent for wiki in ids for sent in wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f461c3e7-f0a5-4f6d-bb81-a72e652cc885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in sent for sent in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64493cf2-0fc2-4ec0-9ff2-0173d57be0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning ml is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data and thus perform tasks without explicit instructions'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930ff8c1-c112-435a-a286-7f565f296952",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter([word for sent in sents for word in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d50ea5-d133-4a68-9411-307c34a62a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(sent, freq, k, t=1):\n",
    "    data = []\n",
    "    n = len(sent)\n",
    "    for i in range(n):\n",
    "        word = sent[i]\n",
    "        j = i - 1\n",
    "        while (i - j) <= k and j >= 0:\n",
    "            # if uniform(0, 1) > (1 - (t/freq[word])): # This function is taken from the second paper by Mikolov et al.\n",
    "            # It's defined in 2.3 Subsampling of Frequent Words.\n",
    "            data.append((word, sent[j]))\n",
    "            j -= 1\n",
    "        j = i + 1\n",
    "        while (j - i) <= k and j < n:\n",
    "            # if uniform(0, 1) > (1 - (t/freq[word])):\n",
    "            data.append((word, sent[j]))\n",
    "            j += 1\n",
    "    return data\n",
    "    \n",
    "def create_training_dataset(sents, freq, k=3):\n",
    "    training_dataset = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        data = create_training_data(sent, freq, k)\n",
    "\n",
    "        training_dataset.extend(data)\n",
    "\n",
    "    return torch.tensor(training_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137f0109-d828-4f21-b8d3-e51422855c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = create_training_dataset(sents, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "854b4e79-9389-483e-b3ab-870130a9b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(training_dataset, batch_size=64, shuffle=True, generator=gen, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62652e5a-0116-4a7b-a845-e369515fc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_skipgram(model, loader): # R is the range from which we take the training samples\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-6)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        X = data[:, 0].to(device)\n",
    "        y = data[:, 1].to(device)\n",
    "        # print(X.device, y.device)\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, F.one_hot(y, num_classes=model.embed.num_embeddings).type(torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "807759e6-d7cb-42d0-b9f8-22cfcd1b82f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Skipgram(vocab_size, \u001b[38;5;241m30\u001b[39m, max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_skipgram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mtrain_skipgram\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, F\u001b[38;5;241m.\u001b[39mone_hot(y, num_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed\u001b[38;5;241m.\u001b[39mnum_embeddings)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/micromamba/envs/torch/lib/python3.9/site-packages/torch/optim/sgd.py:123\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    119\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    120\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[1;32m    121\u001b[0m )\n\u001b[0;32m--> 123\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[0;32m~/micromamba/envs/torch/lib/python3.9/site-packages/torch/optim/sgd.py:299\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 299\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/torch/lib/python3.9/site-packages/torch/optim/sgd.py:352\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m         grad \u001b[38;5;241m=\u001b[39m buf\n\u001b[0;32m--> 352\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Skipgram(vocab_size, 30, max_norm=1)\n",
    "model.to(device)\n",
    "train_skipgram(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2072a16-7bef-4c33-af6c-4a8756ecf5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'small-30-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49340bc2-888e-4d50-bdb3-ce96a6446e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Skipgram(vocab_size, 30, max_norm=1)\n",
    "model.load_state_dict(torch.load('small-30-model.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96b41022-05bc-4bb3-bdd9-aad13e12cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(target, model):\n",
    "    n = model.embed.num_embeddings\n",
    "    target_embed = model.embed(torch.tensor(word2id[target]))\n",
    "    embeds = []\n",
    "    for i in range(n):\n",
    "        if i != word2id[target]:\n",
    "            embeds.append((F.cosine_similarity(target_embed, model.embed(torch.tensor(i)), dim=0), id2word[i]))\n",
    "    embeds.sort(reverse=True)\n",
    "    return embeds[:20]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e46cada-bb58-4731-a560-94a131b983a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.6490, grad_fn=<SumBackward1>), 'translator'),\n",
       " (tensor(0.6440, grad_fn=<SumBackward1>), 'besicovitch'),\n",
       " (tensor(0.6255, grad_fn=<SumBackward1>), 'disappearing'),\n",
       " (tensor(0.6194, grad_fn=<SumBackward1>), 'prokaryotes'),\n",
       " (tensor(0.6055, grad_fn=<SumBackward1>), 'channing'),\n",
       " (tensor(0.5985, grad_fn=<SumBackward1>), 'baic'),\n",
       " (tensor(0.5961, grad_fn=<SumBackward1>), 'snack'),\n",
       " (tensor(0.5912, grad_fn=<SumBackward1>), 'indictment'),\n",
       " (tensor(0.5837, grad_fn=<SumBackward1>), 'gong'),\n",
       " (tensor(0.5789, grad_fn=<SumBackward1>), 'abb'),\n",
       " (tensor(0.5772, grad_fn=<SumBackward1>), 'embezzlement'),\n",
       " (tensor(0.5752, grad_fn=<SumBackward1>), 'pkzip'),\n",
       " (tensor(0.5737, grad_fn=<SumBackward1>), 'fades'),\n",
       " (tensor(0.5695, grad_fn=<SumBackward1>), 'trellix'),\n",
       " (tensor(0.5656, grad_fn=<SumBackward1>), '1k'),\n",
       " (tensor(0.5631, grad_fn=<SumBackward1>), 'owning'),\n",
       " (tensor(0.5629, grad_fn=<SumBackward1>), 'fought'),\n",
       " (tensor(0.5624, grad_fn=<SumBackward1>), 'zbl'),\n",
       " (tensor(0.5615, grad_fn=<SumBackward1>), 'biomemristor'),\n",
       " (tensor(0.5610, grad_fn=<SumBackward1>), 'neuroelectronics')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest('machine', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d64d21e-dde2-4c19-9794-9940b4639cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Linear(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3635355d-1469-4405-8650-cf6abcd641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = a.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "37b72cf9-be3e-4b44-b6c4-32028f0b6f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3143,  0.4608], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.send(None)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
